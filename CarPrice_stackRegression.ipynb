{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1HRgp2l2wQDmTcPcpB00gdRw6HWgO6cjz",
      "authorship_tag": "ABX9TyNjUvtSMvTNzFilIkuSLwrZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pathway2008/CarPrice/blob/main/CarPrice_stackRegression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gOqCT2UZBXs7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('/content/drive/MyDrive/CarPrice/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/CarPrice/test.csv')\n",
        "sub = pd.read_csv('/content/drive/MyDrive/CarPrice/sample_submission.csv')"
      ],
      "metadata": {
        "id": "6ZSTn9n7BrlF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smallest_values = train['생산년도'].nsmallest(2).index\n",
        "train = train.drop(smallest_values)"
      ],
      "metadata": {
        "id": "-WIoGX6oBri0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "largest_values = train['주행거리'].nlargest(3).index\n",
        "train = train.drop(largest_values)"
      ],
      "metadata": {
        "id": "7ylyKJCPBrgx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "3XjCnEAFBreV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ordinal_features = ['브랜드', '차량모델명', '판매도시', '판매구역']\n",
        "\n",
        "for feature in ordinal_features:\n",
        "    le = LabelEncoder()\n",
        "    le = le.fit(train[feature])\n",
        "    train[feature] = le.transform(train[feature])\n",
        "\n",
        "    for label in np.unique(test[feature]):\n",
        "        if label not in le.classes_:\n",
        "            le.classes_ = np.append(le.classes_, label)\n",
        "    test[feature] = le.transform(test[feature])"
      ],
      "metadata": {
        "id": "SwSeCQh2Brb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzh9oAXyB0Wt",
        "outputId": "c886b043-472f-41be-f3c0-dc1526829311"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting catboost\n",
            "  Downloading catboost-1.2-cp310-cp310-manylinux2014_x86_64.whl (98.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.22.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.10.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.13.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2022.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.0.9)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.2.2)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBhnpQIGB0U9",
        "outputId": "0372596b-b660-414c-d6d7-f93478b538aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting optuna\n",
            "  Downloading optuna-3.2.0-py3-none-any.whl (390 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m390.6/390.6 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.11.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cmaes>=0.9.1 (from optuna)\n",
            "  Downloading cmaes-0.9.1-py3-none-any.whl (21 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (23.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.10)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.65.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.2)\n",
            "Installing collected packages: Mako, colorlog, cmaes, alembic, optuna\n",
            "Successfully installed Mako-1.2.4 alembic-1.11.1 cmaes-0.9.1 colorlog-6.7.0 optuna-3.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "LgZz_c_DB0St"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = train.drop(['ID', '가격'], axis=1)\n",
        "y = train['가격']"
      ],
      "metadata": {
        "id": "8CmLQsULB0Ql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "1LgrNtAFB4F-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import StackingRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import optuna\n",
        "from tqdm import tqdm\n",
        "from catboost import Pool"
      ],
      "metadata": {
        "id": "1j0ZU6N7CGU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "    # Define the hyperparameter ranges for CatBoost\n",
        "    catboost_params = {\n",
        "        'loss_function': 'MAE',\n",
        "        'eval_metric': 'MAE',\n",
        "        'random_seed': 42,\n",
        "        'task_type': 'GPU',\n",
        "        'boosting_type': trial.suggest_categorical('boosting_type', ['Plain', 'Ordered']),\n",
        "        'iterations': trial.suggest_int('iterations', 500, 2000),\n",
        "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
        "        'depth': trial.suggest_int('depth', 4, 10),\n",
        "        'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-5, 1e2),\n",
        "        'random_strength': trial.suggest_loguniform('random_strength', 1e-5, 1e2),\n",
        "        'bagging_temperature': trial.suggest_loguniform('bagging_temperature', 0.01, 100.00),\n",
        "        'border_count': trial.suggest_int('border_count', 32, 255),\n",
        "        'use_best_model': True,\n",
        "        'early_stopping_rounds': 100,\n",
        "        'verbose': False\n",
        "    }\n",
        "\n",
        "    # Define the hyperparameter ranges for XGBoost\n",
        "    xgboost_params = {\n",
        "        'objective': 'reg:squarederror',\n",
        "        'eval_metric': 'mae',\n",
        "        'booster': trial.suggest_categorical('booster', ['gbtree', 'dart']),\n",
        "        'eta': trial.suggest_loguniform('eta', 0.001, 0.1),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
        "        'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
        "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
        "        'lambda': trial.suggest_loguniform('lambda', 1e-5, 10.0),\n",
        "        'alpha': trial.suggest_loguniform('alpha', 1e-5, 10.0),\n",
        "        'seed': 42,\n",
        "        'verbosity': 0,\n",
        "        'tree_method': 'gpu_hist'\n",
        "    }\n",
        "\n",
        "\n",
        "    # Create the CatBoost model with the updated parameters\n",
        "    catboost_model = CatBoostRegressor(**catboost_params)\n",
        "\n",
        "    # Fit the CatBoost model to the training data\n",
        "    catboost_model.fit(X_train, y_train, eval_set=(X_valid, y_valid), verbose=False)\n",
        "\n",
        "    # Get the best iteration\n",
        "    best_iteration = catboost_model.best_iteration_\n",
        "\n",
        "# Create a new CatBoost model with the best iteration specified\n",
        "    catboost_model_best = CatBoostRegressor(\n",
        "       **catboost_params,\n",
        "       iterations=best_iteration,\n",
        "       use_best_model=True\n",
        ")\n",
        "\n",
        "    # Fit the CatBoost model with the best iteration to the training data\n",
        "    catboost_model_best.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], verbose=False)\n",
        "\n",
        "    # Make predictions on the validation data\n",
        "    y_pred_valid = catboost_model_best.predict(X_valid)\n",
        "\n",
        "    xgboost_model = XGBRegressor(**xgboost_params)\n",
        "    xgboost_model.fit(X_train, y_train)\n",
        "     # Create the final stacked regression model\n",
        "    stacked_model = StackingRegressor(\n",
        "        estimators=[('catboost', catboost_model), ('xgboost', xgboost_model)],\n",
        "        final_estimator=CatBoostRegressor()\n",
        "    )\n",
        "\n",
        "    # Fit the stacked model to the training data\n",
        "    stacked_model.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the validation data\n",
        "    y_pred = stacked_model.predict(X_valid)\n",
        "\n",
        "    # Calculate the mean absolute error\n",
        "    mae = mean_absolute_error(y_valid, y_pred)\n",
        "\n",
        "    return mae"
      ],
      "metadata": {
        "id": "_3fyzv6PCGSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction='minimize')\n",
        "n_trials = 100\n",
        "with tqdm(total=n_trials) as pbar:\n",
        "    def update_pbar(_, __):\n",
        "        pbar.update(1)\n",
        "\n",
        "    study = optuna.create_study(direction='minimize')\n",
        "    study.optimize(objective, n_trials=n_trials, callbacks=[update_pbar])"
      ],
      "metadata": {
        "id": "pAiY7zpfCGQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dbnmgnnZCGOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Wx5ff3jHCGL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test"
      ],
      "metadata": {
        "id": "EAfWXqELgiYk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from catboost import CatBoostRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.ensemble import StackingRegressor"
      ],
      "metadata": {
        "id": "f2Q5VWrCgj9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training and validation sets\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "GJu88YllgkWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "    # Define the hyperparameter ranges for CatBoost\n",
        "    catboost_params = {\n",
        "        'loss_function': 'MAE',\n",
        "        'eval_metric': 'MAE',\n",
        "        'random_seed': 42,\n",
        "        'task_type': 'GPU',\n",
        "        'boosting_type': trial.suggest_categorical('boosting_type', ['Plain', 'Ordered']),\n",
        "        'iterations': trial.suggest_int('iterations', 500, 2000),\n",
        "        'learning_rate': trial.suggest_categorical('learning_rate', [0.1, 0.2, 0.3, 0.4, 0.5]),\n",
        "        'depth': trial.suggest_int('depth', 4, 10),\n",
        "        'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-5, 1e2),\n",
        "        'random_strength': trial.suggest_loguniform('random_strength', 1e-5, 1e2),\n",
        "        'bagging_temperature': trial.suggest_loguniform('bagging_temperature', 0.01, 100.00),\n",
        "        'border_count': trial.suggest_int('border_count', 32, 255),\n",
        "        'verbose': False\n",
        "    }\n",
        "\n",
        "    # Define the hyperparameter ranges for XGBoost\n",
        "    xgboost_params = {\n",
        "        'objective': 'reg:squarederror',\n",
        "        'eval_metric': 'mae',\n",
        "        'booster': trial.suggest_categorical('booster', ['gbtree', 'dart']),\n",
        "        'eta': trial.suggest_categorical('eta', [0.1, 0.2, 0.3, 0.4, 0.5]),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
        "        'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
        "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
        "        'lambda': trial.suggest_loguniform('lambda', 1e-5, 10.0),\n",
        "        'alpha': trial.suggest_loguniform('alpha', 1e-5, 10.0),\n",
        "        'seed': 42,\n",
        "        'verbosity': 0,\n",
        "        'tree_method': 'gpu_hist'\n",
        "    }\n",
        "\n",
        "    # Create the CatBoost model with the updated parameters\n",
        "    catboost_model = CatBoostRegressor(**catboost_params)\n",
        "\n",
        "    # Fit the CatBoost model to the training data\n",
        "    catboost_model.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the validation data\n",
        "    y_pred_valid = catboost_model.predict(X_valid)\n",
        "\n",
        "    # Create the XGBoost model with the updated parameters\n",
        "    xgboost_model = XGBRegressor(**xgboost_params)\n",
        "\n",
        "    # Fit the XGBoost model to the training data\n",
        "    xgboost_model.fit(X_train, y_train)\n",
        "\n",
        "    # Create the final stacked regression model\n",
        "    stacked_model = StackingRegressor(\n",
        "        estimators=[('catboost', catboost_model), ('xgboost', xgboost_model)],\n",
        "        final_estimator=CatBoostRegressor(task_type='GPU', verbose=False)\n",
        "    )\n",
        "\n",
        "    # Fit the stacked model to the training data\n",
        "    stacked_model.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the validation data\n",
        "    y_pred = stacked_model.predict(X_valid)\n",
        "\n",
        "    # Calculate the mean absolute error\n",
        "    mae = mean_absolute_error(y_valid, y_pred)\n",
        "\n",
        "    return mae"
      ],
      "metadata": {
        "id": "JpCQ8cb5gkUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "계산안됨 성능부족"
      ],
      "metadata": {
        "id": "5qOfCzvJotLg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction='minimize')\n",
        "n_trials = 100\n",
        "with tqdm(total=n_trials) as pbar:\n",
        "    def update_pbar(_, __):\n",
        "        pbar.update(1)\n",
        "\n",
        "    study = optuna.create_study(direction='minimize')\n",
        "    study.optimize(objective, n_trials=n_trials, callbacks=[update_pbar])"
      ],
      "metadata": {
        "id": "NKLKcdvjhIiM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GridSearch로 변경"
      ],
      "metadata": {
        "id": "E7vFAaB2oxV5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from catboost import CatBoostRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.ensemble import StackingRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "ABDn8TxShIf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the parameter grid for CatBoost\n",
        "catboost_param_grid = {\n",
        "    'boosting_type': ['Plain', 'Ordered'],\n",
        "    'iterations': [500, 1000],\n",
        "    'learning_rate': [ 0.2, 0.5],\n",
        "    'depth': [4,  8],\n",
        "    'early_stopping_rounds': [100],\n",
        "    'task_type': ['GPU'],\n",
        "}"
      ],
      "metadata": {
        "id": "RBG5kHmlhId1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the parameter grid for XGBoost\n",
        "xgboost_param_grid = {\n",
        "    'booster': ['gbtree', 'dart'],\n",
        "    'eta': [0.01, 0.05],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'subsample': [0.6, 1.0],\n",
        "    'colsample_bytree': [0.6, 1.0],\n",
        "    'tree_method': ['gpu_hist'],\n",
        "}"
      ],
      "metadata": {
        "id": "auyrv3eZpD2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the CatBoost model\n",
        "catboost_model = CatBoostRegressor(loss_function='MAE', eval_metric='MAE', random_seed=42, verbose=False)\n",
        "\n",
        "# Create the XGBoost model\n",
        "xgboost_model = XGBRegressor(objective='reg:squarederror', eval_metric='mae', seed=42, verbosity=0)"
      ],
      "metadata": {
        "id": "B16_71vjpGKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stacked_model = StackingRegressor(\n",
        "    estimators=[('catboost', catboost_model), ('xgboost', xgboost_model)],\n",
        "    final_estimator=CatBoostRegressor(loss_function='MAE', eval_metric='MAE', random_seed=42, verbose=False)\n",
        ")"
      ],
      "metadata": {
        "id": "fWT8hZ_3pGIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {'catboost__' + k: v for k, v in catboost_param_grid.items()}"
      ],
      "metadata": {
        "id": "VGuhgGdxxUon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform grid search for finding the optimal parameters\n",
        "grid_search = GridSearchCV(estimator=stacked_model, param_grid={'catboost__' + k: v for k, v in catboost_param_grid.items()}, scoring='neg_mean_absolute_error')"
      ],
      "metadata": {
        "id": "bCZp1FghpGGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction='minimize')\n",
        "n_trials = 100\n",
        "with tqdm(total=n_trials) as pbar:\n",
        "    def update_pbar(_, __):\n",
        "        pbar.update(1)\n",
        "\n",
        "    study = optuna.create_study(direction='minimize')\n",
        "    study.optimize(objective, n_trials=n_trials, callbacks=[update_pbar])"
      ],
      "metadata": {
        "id": "4g8ftK9mzfF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_combinations = len(grid_search.param_grid)\n",
        "with tqdm(total=total_combinations, desc=\"Grid Search\", ncols=80) as pbar:\n",
        "    def update_pbar(*args, **kwargs):\n",
        "        pbar.update(1)\n",
        "\n",
        "    grid_search.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "jxjqPhyhpGD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the best parameters and the best estimator\n",
        "best_params = grid_search.best_params_\n",
        "best_estimator = grid_search.best_estimator_"
      ],
      "metadata": {
        "id": "uK01DVfbpGBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_estimator.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "M_km2F93pveX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = best_estimator.predict(X_valid)"
      ],
      "metadata": {
        "id": "925_Mwi2pvcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "stacked regression으로 optimal parameter를 찾는건 불가능\n",
        "optimal을 찾고 stacked regression을 만들어야함"
      ],
      "metadata": {
        "id": "dDbSVb-E4Y18"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "evoNBQSR4YcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FjKp-B2FpvaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pNwf6L1npvX7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}