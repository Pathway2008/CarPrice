{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1BeKQ9mLp4oYqxnTUx-OD8UxtHrVtRk6g",
      "authorship_tag": "ABX9TyPtSj+RpHi7T+yWdpZjVDHX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pathway2008/CarPrice/blob/main/Carprice_GRBT_Stacks_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Un4eoKJXmjp3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('/content/drive/MyDrive/carprice/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/carprice/test.csv')\n",
        "sub = pd.read_csv('/content/drive/MyDrive/carprice/sample_submission.csv')"
      ],
      "metadata": {
        "id": "pQ80jCnqm9fP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smallest_values = train['생산년도'].nsmallest(2).index\n",
        "train = train.drop(smallest_values)"
      ],
      "metadata": {
        "id": "vBhfppYknMm9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "largest_values = train['주행거리'].nlargest(3).index\n",
        "train = train.drop(largest_values)"
      ],
      "metadata": {
        "id": "V-QFvqC_nMlF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import boxcox\n",
        "columns_to_transform = ['주행거리', '배기량']\n",
        "for column in columns_to_transform:\n",
        "    transformed_data, lambda_value = boxcox(train[column])\n",
        "    train[column] = transformed_data"
      ],
      "metadata": {
        "id": "WcU8w73mnTrW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "0aI6cV2InaBG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ordinal_features = ['브랜드', '차량모델명', '판매도시', '판매구역']\n",
        "\n",
        "for feature in ordinal_features:\n",
        "    le = LabelEncoder()\n",
        "    le = le.fit(train[feature])\n",
        "    train[feature] = le.transform(train[feature])\n",
        "\n",
        "    for label in np.unique(test[feature]):\n",
        "        if label not in le.classes_:\n",
        "            le.classes_ = np.append(le.classes_, label)\n",
        "    test[feature] = le.transform(test[feature])"
      ],
      "metadata": {
        "id": "hH6IbocLnZ-1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7S33h_QAnjIt",
        "outputId": "2c9e7e87-732e-4b2f-f91a-7816448e455d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting catboost\n",
            "  Downloading catboost-1.2-cp310-cp310-manylinux2014_x86_64.whl (98.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.22.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.10.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.13.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2022.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.0.9)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.2.2)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "id": "A9UtfknnonDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from catboost import Pool\n",
        "import optuna\n",
        "from tqdm import tqdm\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "from catboost import CatBoostRegressor\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error"
      ],
      "metadata": {
        "id": "_iAOgMyjoN-_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = train.drop(['ID', '가격'], axis=1)\n",
        "y = train['가격']"
      ],
      "metadata": {
        "id": "rksRvRKontEm"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "SlLV-IzanjGW"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_pool = Pool(X_train, y_train)\n",
        "valid_pool = Pool(X_valid, y_valid)"
      ],
      "metadata": {
        "id": "2CeU8STCoKmi"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "    params = {\n",
        "        'loss_function': 'MAE',\n",
        "        'eval_metric': 'MAE',\n",
        "        'random_seed': 42,\n",
        "        'task_type': 'GPU',\n",
        "        'boosting_type': trial.suggest_categorical('boosting_type', ['Plain', 'Ordered']),\n",
        "        'iterations': trial.suggest_int('iterations', 500, 2000),\n",
        "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
        "        'depth': trial.suggest_int('depth', 4, 10),\n",
        "        'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-5, 1e2),\n",
        "        'random_strength': trial.suggest_loguniform('random_strength', 1e-5, 1e2),\n",
        "        'bagging_temperature': trial.suggest_loguniform('bagging_temperature', 0.01, 100.00),\n",
        "        'border_count': trial.suggest_int('border_count', 32, 255),\n",
        "        'use_best_model': True,\n",
        "        'early_stopping_rounds': 100,\n",
        "        'verbose': False\n",
        "    }\n",
        "\n",
        "    # Train the CatBoost model with the current set of parameters\n",
        "    model = CatBoostRegressor(**params)\n",
        "    model.fit(train_pool, eval_set=valid_pool)\n",
        "\n",
        "    # Make predictions on the validation set\n",
        "    y_pred = model.predict(X_valid)\n",
        "\n",
        "    # Calculate the mean absolute error (MAE)\n",
        "    mae = mean_absolute_error(y_valid, y_pred)\n",
        "    return mae"
      ],
      "metadata": {
        "id": "GSq28jxLoKkh"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction='minimize')\n",
        "n_trials = 100\n",
        "with tqdm(total=n_trials) as pbar:\n",
        "    def update_pbar(_, __):\n",
        "        pbar.update(1)\n",
        "\n",
        "    study = optuna.create_study(direction='minimize')\n",
        "    study.optimize(objective, n_trials=n_trials, callbacks=[update_pbar])"
      ],
      "metadata": {
        "id": "dx_Dl3B7oKik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_params = study.best_params\n",
        "best_score = study.best_value\n",
        "print(\"Best Parameters:\", best_params)\n",
        "print(\"Best MAE:\", best_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5EFH-QC9oUgT",
        "outputId": "5ff4bbcf-2864-4316-f78f-7e2e0570db71"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'boosting_type': 'Plain', 'iterations': 1997, 'learning_rate': 0.08862372339654186, 'depth': 9, 'l2_leaf_reg': 2.1031379341857397, 'random_strength': 15.074833000342615, 'bagging_temperature': 0.30077839937910833, 'border_count': 250}\n",
            "Best MAE: 5.85601717965721\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_model = CatBoostRegressor(**best_params)\n",
        "final_model.fit(train_pool)"
      ],
      "metadata": {
        "id": "1h7s3g0AoUeD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_cat_optuna = test.drop(['ID'],axis=1)\n",
        "pred = final_model.predict(test_cat_optuna)"
      ],
      "metadata": {
        "id": "s5Z2ieQ1oUbz"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sub['가격'] = pred\n",
        "sub.to_csv('cat_opnuta+boxcox.csv', index = False)"
      ],
      "metadata": {
        "id": "A2qdY6wUoYi7"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GBRTmodel (no scaling)"
      ],
      "metadata": {
        "id": "sM8K0_KmRbHW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ray"
      ],
      "metadata": {
        "id": "L6YlNs8uRzEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import ray\n",
        "from ray import tune\n",
        "from tqdm import tqdm\n",
        "import torch"
      ],
      "metadata": {
        "id": "kKR1Nb6woYgt"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = train.drop(['ID', '가격'], axis=1)\n",
        "y = train['가격']"
      ],
      "metadata": {
        "id": "RIYMALAvR52j"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "Tr0O7T2WR50g"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "    # Define the search space for the hyperparameters\n",
        "    params = {\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
        "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
        "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 4),\n",
        "        'max_features': trial.suggest_categorical('max_features', ['auto', 'sqrt']),\n",
        "        'subsample': trial.suggest_float('subsample', 0.8, 1.0)\n",
        "    }\n",
        "\n",
        "    # Initialize the GBRT model with the suggested parameters\n",
        "    model = GradientBoostingRegressor(**params)\n",
        "\n",
        "    # Move the model to GPU\n",
        "    device = torch.device('cuda')\n",
        "    model.to(device)\n",
        "\n",
        "    # Move the training and validation data to GPU\n",
        "    X_train_tensor = torch.tensor(X_train.values, device=device, dtype=torch.float32)\n",
        "    y_train_tensor = torch.tensor(y_train.values, device=device, dtype=torch.float32)\n",
        "    X_valid_tensor = torch.tensor(X_valid.values, device=device, dtype=torch.float32)\n",
        "\n",
        "    # Fit the model to the training data\n",
        "    model.fit(X_train_tensor, y_train_tensor)\n",
        "\n",
        "    # Make predictions on the validation set\n",
        "    y_pred_tensor = model.predict(X_valid_tensor)\n",
        "\n",
        "    # Move the predictions back to CPU for evaluation\n",
        "    y_pred = y_pred_tensor.detach().cpu().numpy()\n",
        "    y_valid_cpu = y_valid.to_numpy()\n",
        "\n",
        "    # Compute the mean absolute error\n",
        "    mae = mean_absolute_error(y_valid_cpu, y_pred)\n",
        "\n",
        "    return mae"
      ],
      "metadata": {
        "id": "gEDYIBOxR5yd"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "1NhoH7GTW6ol"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#study = optuna.create_study(direction='minimize')\n",
        "n_trials = 100\n",
        "with tqdm(total=n_trials) as pbar:\n",
        "    def update_pbar(_, __):\n",
        "        pbar.update(1)\n",
        "\n",
        "    study = optuna.create_study(direction='minimize')\n",
        "    study.optimize(objective, n_trials=n_trials, callbacks=[update_pbar])"
      ],
      "metadata": {
        "id": "TuLLpS3cSMwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stacked Regression\n",
        "(xgb,lgb,cat)"
      ],
      "metadata": {
        "id": "vGpb30pO2o1C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import StackingRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "from sklearn.metrics import mean_absolute_error"
      ],
      "metadata": {
        "id": "3P6Dx80K2msm"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = train.drop(['ID', '가격'], axis=1)\n",
        "y = train['가격']\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "bjHPCC0gSbua"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_model = XGBRegressor(tree_method='gpu_hist', gpu_id=0)\n",
        "lgbm_model = LGBMRegressor(device='gpu')\n",
        "catboost_model = CatBoostRegressor(task_type ='GPU')"
      ],
      "metadata": {
        "id": "mG_tgrb33AJ7"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stacked_model = StackingRegressor(\n",
        "    estimators=[('xgb', xgb_model), ('lgbm', lgbm_model), ('catboost', catboost_model)],\n",
        "    final_estimator=XGBRegressor(tree_method='gpu_hist', gpu_id=0)  # Use XGBoost as the final estimator\n",
        ")"
      ],
      "metadata": {
        "id": "NMDV2I2K3CWo"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone --recursive https://github.com/Microsoft/LightGBM"
      ],
      "metadata": {
        "id": "wl5MgSam4qko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/LightGBM"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzpTF8Ha4tsJ",
        "outputId": "99e4a6c2-5292-479a-831f-03457d6888c8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/LightGBM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir build"
      ],
      "metadata": {
        "id": "z-c4-EyR4uc5"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cmake -DUSE_GPU=1"
      ],
      "metadata": {
        "id": "gQ7Mc5Oa4Aog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!make -j$(nproc)\n",
        "!sudo apt-get -y install python-pip\n",
        "!sudo -H pip install setuptools pandas numpy scipy scikit-learn -U"
      ],
      "metadata": {
        "id": "7Akzbr0O4DkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/LightGBM/python-package/\n",
        "!sudo python setup.py install --precompile"
      ],
      "metadata": {
        "id": "W6XETrUe4Dhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r /opt/conda/lib/python3.6/site-packages/lightgbm\n",
        "!git clone --recursive https://github.com/Microsoft/LightGBM"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJZMnkMu-Rbu",
        "outputId": "ec0eda2d-eb71-44a7-f8b5-e55e30073f29"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/opt/conda/lib/python3.6/site-packages/lightgbm': No such file or directory\n",
            "Cloning into 'LightGBM'...\n",
            "remote: Enumerating objects: 29746, done.\u001b[K\n",
            "remote: Counting objects: 100% (3477/3477), done.\u001b[K\n",
            "remote: Compressing objects: 100% (370/370), done.\u001b[K\n",
            "remote: Total 29746 (delta 3222), reused 3269 (delta 3106), pack-reused 26269\u001b[K\n",
            "Receiving objects: 100% (29746/29746), 20.65 MiB | 15.30 MiB/s, done.\n",
            "Resolving deltas: 100% (22107/22107), done.\n",
            "Submodule 'include/boost/compute' (https://github.com/boostorg/compute) registered for path 'external_libs/compute'\n",
            "Submodule 'eigen' (https://gitlab.com/libeigen/eigen.git) registered for path 'external_libs/eigen'\n",
            "Submodule 'external_libs/fast_double_parser' (https://github.com/lemire/fast_double_parser.git) registered for path 'external_libs/fast_double_parser'\n",
            "Submodule 'external_libs/fmt' (https://github.com/fmtlib/fmt.git) registered for path 'external_libs/fmt'\n",
            "Cloning into '/content/LightGBM/python-package/LightGBM/external_libs/compute'...\n",
            "remote: Enumerating objects: 21733, done.        \n",
            "remote: Counting objects: 100% (5/5), done.        \n",
            "remote: Compressing objects: 100% (4/4), done.        \n",
            "remote: Total 21733 (delta 1), reused 3 (delta 1), pack-reused 21728        \n",
            "Receiving objects: 100% (21733/21733), 8.51 MiB | 16.51 MiB/s, done.\n",
            "Resolving deltas: 100% (17567/17567), done.\n",
            "Cloning into '/content/LightGBM/python-package/LightGBM/external_libs/eigen'...\n",
            "remote: Enumerating objects: 119575, done.        \n",
            "remote: Counting objects: 100% (1254/1254), done.        \n",
            "remote: Compressing objects: 100% (404/404), done.        \n",
            "remote: Total 119575 (delta 883), reused 1203 (delta 849), pack-reused 118321        \n",
            "Receiving objects: 100% (119575/119575), 103.68 MiB | 20.80 MiB/s, done.\n",
            "Resolving deltas: 100% (98718/98718), done.\n",
            "Cloning into '/content/LightGBM/python-package/LightGBM/external_libs/fast_double_parser'...\n",
            "remote: Enumerating objects: 781, done.        \n",
            "remote: Counting objects: 100% (180/180), done.        \n",
            "remote: Compressing objects: 100% (66/66), done.        \n",
            "remote: Total 781 (delta 124), reused 131 (delta 103), pack-reused 601        \n",
            "Receiving objects: 100% (781/781), 833.45 KiB | 17.73 MiB/s, done.\n",
            "Resolving deltas: 100% (395/395), done.\n",
            "Cloning into '/content/LightGBM/python-package/LightGBM/external_libs/fmt'...\n",
            "remote: Enumerating objects: 32488, done.        \n",
            "remote: Counting objects: 100% (3255/3255), done.        \n",
            "remote: Compressing objects: 100% (193/193), done.        \n",
            "remote: Total 32488 (delta 3084), reused 3126 (delta 3038), pack-reused 29233        \n",
            "Receiving objects: 100% (32488/32488), 13.85 MiB | 14.38 MiB/s, done.\n",
            "Resolving deltas: 100% (22043/22043), done.\n",
            "Submodule path 'external_libs/compute': checked out '36350b7de849300bd3d72a05d8bf890ca405a014'\n",
            "Submodule path 'external_libs/eigen': checked out '3147391d946bb4b6c68edd901f2add6ac1f31f8c'\n",
            "Submodule path 'external_libs/fast_double_parser': checked out 'ace60646c02dc54c57f19d644e49a61e7e7758ec'\n",
            "Submodule 'benchmark/dependencies/abseil-cpp' (https://github.com/abseil/abseil-cpp.git) registered for path 'external_libs/fast_double_parser/benchmarks/dependencies/abseil-cpp'\n",
            "Submodule 'benchmark/dependencies/double-conversion' (https://github.com/google/double-conversion.git) registered for path 'external_libs/fast_double_parser/benchmarks/dependencies/double-conversion'\n",
            "Cloning into '/content/LightGBM/python-package/LightGBM/external_libs/fast_double_parser/benchmarks/dependencies/abseil-cpp'...\n",
            "remote: Enumerating objects: 22355, done.        \n",
            "remote: Counting objects: 100% (3747/3747), done.        \n",
            "remote: Compressing objects: 100% (1096/1096), done.        \n",
            "remote: Total 22355 (delta 2812), reused 2822 (delta 2651), pack-reused 18608        \n",
            "Receiving objects: 100% (22355/22355), 13.01 MiB | 15.17 MiB/s, done.\n",
            "Resolving deltas: 100% (17628/17628), done.\n",
            "Cloning into '/content/LightGBM/python-package/LightGBM/external_libs/fast_double_parser/benchmarks/dependencies/double-conversion'...\n",
            "remote: Enumerating objects: 1387, done.        \n",
            "remote: Counting objects: 100% (231/231), done.        \n",
            "remote: Compressing objects: 100% (124/124), done.        \n",
            "remote: Total 1387 (delta 126), reused 185 (delta 98), pack-reused 1156        \n",
            "Receiving objects: 100% (1387/1387), 7.16 MiB | 968.00 KiB/s, done.\n",
            "Resolving deltas: 100% (898/898), done.\n",
            "Submodule path 'external_libs/fast_double_parser/benchmarks/dependencies/abseil-cpp': checked out 'd936052d32a5b7ca08b0199a6724724aea432309'\n",
            "Submodule path 'external_libs/fast_double_parser/benchmarks/dependencies/double-conversion': checked out 'f4cb2384efa55dee0e6652f8674b05763441ab09'\n",
            "Submodule path 'external_libs/fmt': checked out 'b6f4ceaed0a0a24ccf575fab6c56dd50ccf6f1a9'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y libboost-all-dev"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvEAn4ek-YyE",
        "outputId": "30a1b833-c837-457d-a90a-3fee1be76f0d"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libboost-all-dev is already the newest version (1.71.0.0ubuntu2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 46 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update --fix-missing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7Heajts-Yv5",
        "outputId": "4fe39f86-b289-4d91-8520-4eb183a84abd"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease [3,622 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease [1,581 B]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  Packages [1,012 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "Hit:5 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease\n",
            "Get:6 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
            "Hit:8 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Hit:9 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "Get:10 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2,781 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
            "Hit:12 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1,356 kB]\n",
            "Hit:14 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Get:15 http://archive.ubuntu.com/ubuntu focal-updates/restricted amd64 Packages [2,490 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [1,060 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu focal-security/restricted amd64 Packages [2,352 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [3,260 kB]\n",
            "Fetched 14.7 MB in 3s (4,819 kB/s)\n",
            "Reading package lists... Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cd LightGBM\n",
        "#rm -r build\n",
        "mkdir build\n",
        "cd build\n",
        "cmake -DUSE_GPU=1 -DOpenCL_LIBRARY=/usr/local/cuda/lib64/libOpenCL.so.1.0 -DOpenCL_INCLUDE_DIR=/usr/local/cuda/include/ ..\n",
        "make -j$(nproc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FOsdt7N-Ytn",
        "outputId": "1b1ac568-0c33-42b0-d323-f49eeb86bc2b"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- The C compiler identification is GNU 9.4.0\n",
            "-- The CXX compiler identification is GNU 9.4.0\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Check for working C compiler: /usr/bin/cc - skipped\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- Found OpenMP_C: -fopenmp (found version \"4.5\") \n",
            "-- Found OpenMP_CXX: -fopenmp (found version \"4.5\") \n",
            "-- Found OpenMP: TRUE (found version \"4.5\")  \n",
            "-- Looking for CL_VERSION_3_0\n",
            "-- Looking for CL_VERSION_3_0 - found\n",
            "-- Found OpenCL: /usr/local/cuda/lib64/libOpenCL.so.1.0 (found version \"3.0\") \n",
            "-- OpenCL include directory: /usr/local/cuda/include\n",
            "-- Found Boost: /usr/lib/x86_64-linux-gnu/cmake/Boost-1.71.0/BoostConfig.cmake (found suitable version \"1.71.0\", minimum required is \"1.56.0\") found components: filesystem system \n",
            "-- Performing Test MM_PREFETCH\n",
            "-- Performing Test MM_PREFETCH - Success\n",
            "-- Using _mm_prefetch\n",
            "-- Performing Test MM_MALLOC\n",
            "-- Performing Test MM_MALLOC - Success\n",
            "-- Using _mm_malloc\n",
            "-- Configuring done\n",
            "-- Generating done\n",
            "-- Build files have been written to: /content/LightGBM/python-package/LightGBM/build\n",
            "[  1%] Building CXX object CMakeFiles/lightgbm_capi_objs.dir/src/c_api.cpp.o\n",
            "[  3%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/boosting/boosting.cpp.o\n",
            "[  5%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/boosting/cuda/cuda_score_updater.cpp.o\n",
            "[  7%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/boosting/gbdt.cpp.o\n",
            "[  7%] Built target lightgbm_capi_objs\n",
            "[  9%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/boosting/gbdt_model_text.cpp.o\n",
            "[ 10%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/boosting/gbdt_prediction.cpp.o\n",
            "[ 12%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/boosting/prediction_early_stop.cpp.o\n",
            "[ 14%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/boosting/sample_strategy.cpp.o\n",
            "[ 16%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/cuda/cuda_utils.cpp.o\n",
            "[ 18%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/io/bin.cpp.o\n",
            "[ 20%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/io/config.cpp.o\n",
            "[ 21%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/io/config_auto.cpp.o\n",
            "[ 23%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/io/cuda/cuda_column_data.cpp.o\n",
            "[ 25%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/io/cuda/cuda_metadata.cpp.o\n",
            "[ 27%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/io/cuda/cuda_row_data.cpp.o\n",
            "[ 29%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/io/cuda/cuda_tree.cpp.o\n",
            "[ 30%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/io/dataset.cpp.o\n",
            "[ 32%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/io/dataset_loader.cpp.o\n",
            "[ 34%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/io/file_io.cpp.o\n",
            "[ 36%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/io/json11.cpp.o\n",
            "[ 38%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/io/metadata.cpp.o\n",
            "[ 40%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/io/parser.cpp.o\n",
            "[ 41%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/io/train_share_states.cpp.o\n",
            "[ 43%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/io/tree.cpp.o\n",
            "[ 45%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/metric/cuda/cuda_binary_metric.cpp.o\n",
            "[ 47%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/metric/cuda/cuda_pointwise_metric.cpp.o\n",
            "[ 49%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/metric/cuda/cuda_regression_metric.cpp.o\n",
            "[ 50%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/metric/dcg_calculator.cpp.o\n",
            "[ 52%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/metric/metric.cpp.o\n",
            "[ 54%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/network/linker_topo.cpp.o\n",
            "[ 56%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/network/linkers_mpi.cpp.o\n",
            "[ 58%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/network/linkers_socket.cpp.o\n",
            "[ 60%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/network/network.cpp.o\n",
            "[ 61%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/objective/cuda/cuda_binary_objective.cpp.o\n",
            "[ 63%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/objective/cuda/cuda_multiclass_objective.cpp.o\n",
            "[ 65%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/objective/cuda/cuda_rank_objective.cpp.o\n",
            "[ 67%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/objective/cuda/cuda_regression_objective.cpp.o\n",
            "[ 69%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/objective/objective_function.cpp.o\n",
            "[ 70%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/treelearner/cuda/cuda_best_split_finder.cpp.o\n",
            "[ 72%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/treelearner/cuda/cuda_data_partition.cpp.o\n",
            "[ 74%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/treelearner/cuda/cuda_histogram_constructor.cpp.o\n",
            "[ 76%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/treelearner/cuda/cuda_leaf_splits.cpp.o\n",
            "[ 78%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/treelearner/cuda/cuda_single_gpu_tree_learner.cpp.o\n",
            "[ 80%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/treelearner/data_parallel_tree_learner.cpp.o\n",
            "[ 81%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/treelearner/feature_parallel_tree_learner.cpp.o\n",
            "[ 83%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/treelearner/gpu_tree_learner.cpp.o\n",
            "[ 85%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/treelearner/gradient_discretizer.cpp.o\n",
            "[ 87%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/treelearner/linear_tree_learner.cpp.o\n",
            "[ 89%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/treelearner/serial_tree_learner.cpp.o\n",
            "[ 90%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/treelearner/tree_learner.cpp.o\n",
            "[ 92%] Building CXX object CMakeFiles/lightgbm_objs.dir/src/treelearner/voting_parallel_tree_learner.cpp.o\n",
            "[ 92%] Built target lightgbm_objs\n",
            "[ 94%] Building CXX object CMakeFiles/lightgbm.dir/src/main.cpp.o\n",
            "[ 96%] Linking CXX shared library /content/LightGBM/python-package/LightGBM/lib_lightgbm.so\n",
            "[ 96%] Built target _lightgbm\n",
            "[ 98%] Building CXX object CMakeFiles/lightgbm.dir/src/application/application.cpp.o\n",
            "[100%] Linking CXX executable /content/LightGBM/python-package/LightGBM/lightgbm\n",
            "[100%] Built target lightgbm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#/usr/local/cuda/lib64/libOpenCL.so.1.0"
      ],
      "metadata": {
        "id": "mGdE71H3-Yru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stacked_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "1rzPu6P93EwP",
        "outputId": "f7d17b2f-d837-42fd-d6ef-ee807eebceaf"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "error",
          "ename": "LightGBMError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLightGBMError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-82bc9ebecdc7>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstacked_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_stacking.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    956\u001b[0m         \"\"\"\n\u001b[1;32m    957\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 958\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_stacking.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0;31m# base estimators will be used in transform, predict, and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0;31m# predict_proba. They are exposed publicly.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m             self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n\u001b[0m\u001b[1;32m    210\u001b[0m                 \u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_fit_single_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_estimators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1086\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1088\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1089\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py\u001b[0m in \u001b[0;36m_fit_single_estimator\u001b[0;34m(estimator, X, y, sample_weight, message_clsname, message)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    893\u001b[0m             callbacks=None, init_model=None):\n\u001b[1;32m    894\u001b[0m         \u001b[0;34m\"\"\"Docstring is inherited from the LGBMModel.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         super().fit(X, y, sample_weight=sample_weight, init_score=init_score,\n\u001b[0m\u001b[1;32m    896\u001b[0m                     \u001b[0meval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_sample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                     \u001b[0meval_init_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_init_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_metric\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    746\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m         self._Booster = train(\n\u001b[0m\u001b[1;32m    749\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mtrain_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;31m# construct booster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0mbooster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBooster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_valid_contain_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m             \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_train_data_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, train_set, model_file, model_str, silent)\u001b[0m\n\u001b[1;32m   2608\u001b[0m             \u001b[0mparams_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam_dict_to_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2609\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2610\u001b[0;31m             _safe_call(_LIB.LGBM_BoosterCreate(\n\u001b[0m\u001b[1;32m   2611\u001b[0m                 \u001b[0mtrain_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2612\u001b[0m                 \u001b[0mc_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_safe_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    123\u001b[0m     \"\"\"\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLGBM_GetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLightGBMError\u001b[0m: GPU Tree Learner was not enabled in this build.\nPlease recompile with CMake option -DUSE_GPU=1"
          ]
        }
      ]
    }
  ]
}